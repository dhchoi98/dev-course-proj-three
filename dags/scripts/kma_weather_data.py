# ÏÑ§Î™Ö: ÎÇ†Ïî® ÏòàÎ≥¥ Îç∞Ïù¥ÌÑ∞Î•º ÏàòÏßëÌïòÍ≥† Ï≤òÎ¶¨ÌïòÎäî Í∏∞Îä•ÏùÑ Îã¥ÎãπÌï©ÎãàÎã§.
# Ïô∏Î∂Ä APIÏóêÏÑú ÎÇ†Ïî® Îç∞Ïù¥ÌÑ∞Î•º ÏàòÏßëÌïòÍ≥†, S3ÏóêÏÑú Ï¢åÌëú Îç∞Ïù¥ÌÑ∞Î•º Î°úÎìúÌïòÎ©∞,
# Îç∞Ïù¥ÌÑ∞Î•º ÌîºÎ≤ó, Ïà´Ïûê Î≥ÄÌôò, ÏÉÅÌÉú Îß§Ìïë(SKY, PTY), Í∞ïÌíç Î∞è Î∂àÏæåÏßÄÏàò Í≤ΩÍ≥†Î•º Ï∂îÍ∞ÄÌïòÏó¨ Ï†ïÏ†úÌï©ÎãàÎã§.

import pandas as pd
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed
import boto3
from io import StringIO
from botocore.exceptions import NoCredentialsError
from weather_config import logger, S3_BUCKET, S3_COORDINATES_PATH, API_URL, AUTH_KEY, BASE_DATE, BASE_TIME, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_DEFAULT_REGION

def load_locations_from_s3(bucket, key):
    try:
        s3 = boto3.client(
            's3',
            aws_access_key_id=AWS_ACCESS_KEY_ID,
            aws_secret_access_key=AWS_SECRET_ACCESS_KEY,
            region_name=AWS_DEFAULT_REGION
        )
        obj = s3.get_object(Bucket=bucket, Key=key)
        csv_content = obj['Body'].read().decode('utf-8')
        df = pd.read_csv(StringIO(csv_content), encoding='utf-8')
        
        required_columns = ['level1', 'level2', 'nx', 'ny']
        if not all(col in df.columns for col in required_columns):
            logger.error(f"coordinates.csvÏóê ÌïÑÏàò Ïª¨ÎüºÏù¥ ÎàÑÎùΩÎêòÏóàÏäµÎãàÎã§: {required_columns}")
            raise ValueError("Missing required columns in coordinates.csv")
        
        df['level2'] = df['level2'].fillna('')
        locations = df.to_dict('records')
        logger.info(f"Loaded {len(locations)} locations from s3://{bucket}/{key}")
        return locations
    except NoCredentialsError:
        logger.error("AWS credentials not found")
        raise
    except Exception as e:
        logger.error(f"Error loading coordinates.csv from S3: {str(e)}")
        raise

def fetch_data():
    results = []
    locations = load_locations_from_s3(S3_BUCKET, S3_COORDINATES_PATH)

    def fetch_single(location):
        location_name = f"{location['level1']} {location['level2']}".strip() if location['level2'] else location['level1']
        broad_location = location['level1']
        logger.info(f"{location_name} ÏßÄÏó≠ Îç∞Ïù¥ÌÑ∞ ÏàòÏßë Ï§ë...")
        params = {
            "pageNo": 1,
            "numOfRows": 1000,
            "dataType": "JSON",
            "base_date": BASE_DATE,
            "base_time": BASE_TIME,
            "nx": location['nx'],
            "ny": location['ny'],
            "authKey": AUTH_KEY
        }
        try:
            response = requests.get(API_URL, params=params)
            response.raise_for_status()
            data = response.json()
            if 'response' in data and 'body' in data['response'] and 'items' in data['response']['body']:
                items = data['response']['body']['items']['item']
                if not items:
                    logger.warning(f"{location_name} ÏßÄÏó≠ Îç∞Ïù¥ÌÑ∞Í∞Ä ÎπÑÏñ¥ ÏûàÏäµÎãàÎã§.")
                    return pd.DataFrame()
                df = pd.DataFrame(items)
                df['LOCATION'] = location_name
                df['BROAD_LOCATION'] = broad_location
                return df
            else:
                logger.warning(f"{location_name} ÏßÄÏó≠ Îç∞Ïù¥ÌÑ∞ ÏóÜÏùå: ÏùëÎãµ Íµ¨Ï°∞ ÎπÑÏ†ïÏÉÅ")
                return pd.DataFrame()
        except requests.RequestException as e:
            logger.error(f"{location_name} API ÏöîÏ≤≠ Ïã§Ìå®: {str(e)}")
            return pd.DataFrame()

    with ThreadPoolExecutor(max_workers=10) as executor:
        futures = [executor.submit(fetch_single, loc) for loc in locations]
        for future in as_completed(futures):
            df = future.result()
            if not df.empty:
                results.append(df)

    return pd.concat(results, ignore_index=True) if results else pd.DataFrame()

def process_data(df):
    if df.empty:
        logger.warning("Ï≤òÎ¶¨Ìï† Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏäµÎãàÎã§.")
        return df

    try:
        df_pivot = df.pivot(
            index=['baseDate', 'baseTime', 'fcstDate', 'fcstTime', 'nx', 'ny', 'LOCATION', 'BROAD_LOCATION'],
            columns='category',
            values='fcstValue'
        ).reset_index()

        numeric_columns = ['WSD', 'VEC', 'TMP', 'POP', 'REH']
        for col in numeric_columns:
            if col in df_pivot.columns:
                df_pivot[col] = pd.to_numeric(df_pivot[col], errors='coerce')

        sky_map = {'1': 'ÎßëÏùå', '2': 'Íµ¨Î¶ÑÏ°∞Í∏à', '3': 'Íµ¨Î¶ÑÎßéÏùå', '4': 'ÌùêÎ¶º'}
        df_pivot['SKY'] = df_pivot.get('SKY', 'ÏïåÏàòÏóÜÏùå').map(lambda x: sky_map.get(x, x))

        def convert_pty(x):
            try:
                val = float(x)
                return {0: 'ÏóÜÏùå', 1: 'ÎπÑ', 2: 'ÎπÑ/Îàà', 3: 'Îàà', 4: 'Îàà/ÎπÑ'}.get(val, x)
            except:
                return x
        df_pivot['PTY'] = df_pivot.get('PTY', 'ÏïåÏàòÏóÜÏùå').apply(convert_pty)

        df_pivot['STRONG_WIND_ALERT'] = df_pivot['WSD'].apply(
            lambda x: 'Yes' if pd.notna(x) and x >= 14 else 'No'
        )

        if 'TMP' in df_pivot.columns and 'REH' in df_pivot.columns:
            df_pivot['DI'] = 0.81 * df_pivot['TMP'] + 0.01 * df_pivot['REH'] * (0.99 * df_pivot['TMP'] - 14.3) + 46.3
            df_pivot['DISCOMFORT_ALERT'] = df_pivot['DI'].apply(
                lambda x: 'Îß§Ïö∞ ÎÜíÏùå üü•' if x >= 80 else 'ÎÜíÏùå üüß' if x >= 75 else 'Î≥¥ÌÜµ üü®'
            )
        else:
            df_pivot['DI'] = None
            df_pivot['DISCOMFORT_ALERT'] = 'Ïïå Ïàò ÏóÜÏùå'

        df_pivot.rename(columns={
            'baseDate': 'BASE_DATE',
            'baseTime': 'BASE_TIME',
           'ducstDate': 'FCST_DATE',
            'fcstTime': 'FCST_TIME',
            'nx': 'NX',
            'ny': 'NY'
        }, inplace=True)

        df_pivot = df_pivot[df_pivot['FCST_DATE'] >= BASE_DATE]
        return df_pivot
    except Exception as e:
        logger.error(f"Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨ Ï§ë Ïò§Î•ò: {str(e)}")
        return pd.DataFrame()